{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-chess==0.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML, display\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "svg {\n",
    "    width:40% !important;\n",
    "    height:40% !important;\n",
    "}\n",
    "\n",
    ".container { \n",
    "    width:100% !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benutzerhandbuch\n",
    "\n",
    "\n",
    "## Bedienen des Programms\n",
    "\n",
    "Beim Spielstart wird zunächst das aktuelle Schachbrett in der Konsole ausgegeben. \n",
    "Ist der Spieler, der an der Reihe ist, ein menschlicher Spieler, so wird zusätzlich eine Liste aller legalen Züge ausgegeben. Dann wird der Spieler zur Eingabe einer dieser Züge aufgefordert. Die Eingabe muss in den ersten zwei Zeichen das Feld enthalten, von dem eine Figur aus bewegt werden soll, und bei Zeichen drei und vier die Felder, auf die die Figur bewegt werden soll. Ist der eingegebene Zug möglich, so wird dieser auf dem Schachfeld durchgeführt und erneut ausgegeben. Dann ist der nächste Spieler am Zug. Andernfalls wird die Aufforderung zur Eingabe eines Zuges so lange wiederholt, bis eine legale Eingabe vorliegt und der Zug durchgeführt werden kann.\n",
    "\n",
    "Sobald das Spiel zu Ende ist, wird der Sieger des Spiels genannt. Danach wird der Spieler gefragt, ob er mit den gleichen Einstellungen das Spiel nochmal wiederholen möchte. Mit Eingabe einer \"1\" und bestätigen durch die 'Enter' Taste kann dies bejaht werden. So wird das Spiel nochmal mit den gleichen Einstellungen wiederholt. Andernfalls wird das Programm beendet.\n",
    "\n",
    "Jederzeit kann mit der Tastenkombination 'Strg' + 'C' das Programm und somit auch das Spiel vorläufig beendet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zugfindung durch KI\n",
    "\n",
    "Die zentrale Aufgabe der KI ist es, den best möglichen Zug für eine gegebene Situation zu finden. Wie in Kapitel INSERT erwähnt, wird es dazu von dem `ChessMaster` aufgefordert und dazu das aktuelle board mit übergeben. Dazu müssen zunächst einige Konstanten definiert werden, die die Einstellungen des Spiels festlegen, wie die Faktorisierung der einzelnen Bewertungsfunktionen (siehe unten) oder maximale Tiefe bzw. Zeitlimit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENING_MAX_FULLMOVE_NUM = 6\n",
    "FINISHING_MAX_PIECES = 13\n",
    "MAX_BOARD_VALUE = float(\"inf\")\n",
    "MAX_DEPTH = 8\n",
    "TIME_LIMIT=45\n",
    "\n",
    "BOARD_VALUE_FACTOR = 50\n",
    "ATTACKED_PIECES_FACTOR = 10\n",
    "BOARD_POSITIONS_FACTOR = 25\n",
    "OPP_BOARD_POSITIONS_FACTOR = 25\n",
    "KING_SAFETY_FACTOR = 5\n",
    "OPP_KING_SAFETY_FACTOR = 5\n",
    "MOBILITY_FACTOR = 4\n",
    "\n",
    "def get_evaluation_func_dict():\n",
    "    return {\n",
    "        get_board_value: BOARD_VALUE_FACTOR, \n",
    "        get_attacked_pieces_value: ATTACKED_PIECES_FACTOR, \n",
    "        get_board_positions_value: BOARD_POSITIONS_FACTOR, \n",
    "        get_opp_board_positions_value: OPP_BOARD_POSITIONS_FACTOR, \n",
    "        calculate_king_zone_safety: KING_SAFETY_FACTOR, \n",
    "        calculate_opp_king_zone_safety: OPP_KING_SAFETY_FACTOR, \n",
    "        calculate_mobility_value: MOBILITY_FACTOR\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können Züge wie folgt von der KI berechnet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_move(board):       \n",
    "        opening_book = import_opening_book(OPENING_BOOK_LOC)\n",
    "        \n",
    "        if board.fullmove_number <= OPENING_MAX_FULLMOVE_NUM:\n",
    "            move = get_opening_move(board, opening_book)\n",
    "            if not move is None:\n",
    "                return move\n",
    "        \n",
    "\n",
    "        return iterative_deepening(board, MAX_DEPTH, evaluate_board, get_evaluation_func_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst wird versucht, sollte das Spiel noch innerhalb der Phase sein, in der das Opening Book einen Zug finden könnte, über diesen einen Zug zu erhalten.\n",
    "Andernfalls wird die Funktion des \"Iterative Deepening\", aufgerufen und der Rückgabewert dieser Funktion als durchzuführender Zug ausgewählt und somit zurückgegeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einbinden und Verwendung von Opening-Books\n",
    "\n",
    "Im Fall, dass sich das Spiel noch im Anfangszustand befindet, kann ein Opening Book zur Hilfe genommen werden, um einen passenden Zug zu finden.\n",
    "\n",
    "Opening-Books sind ein wesentlicher Bestandteil der Schach-KI, da diese aus einer großen Anzahl von Eröffnungszügen bestehen. Hierbei wurden die Opening-Books bereits analysiert und konnten durch Überprüfungen als gute Eröffnungen identifiziert werden.\n",
    "\n",
    "Zur Verwendung dieser Bücher müssen diese Dateien, die im .bin-Format vorliegen, in eine Variable geladen werden, da später auf diese Bücher mittels Funktionen zugegriffen werden soll. Damit die Eröffnungszüge in einer Variable gespeichert werden können, muss der Pfad zu dem Buch vorliegen, der im folgenden Codeausschnitt in eine globale Konstante `OPENING_BOOK_LOC` geschrieben wurde. Dies findet ebenfalls in der Datei `player/ai.py`statt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENING_BOOK_LOC = \"./res/polyglot/Performance.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das Laden eines Buches in eine Variable wird die Funktion `import_opening_book(self, book_location)` genutzt. Diese hat die Eigenschaft, dass sie als Übergabeparameter eine Konstante erhält, die den Pfad zu dem zu importierenden Opening-Book enthält.\n",
    "\n",
    "Innerhalb der `import_opening_book` Funktion wird mittels einer If-Verzweigung überprüft, ob der angegebene Pfad eine Datei ist. Sollte dies zutreffen, dann wird, inklusive des Buchpfades, die Funktion `polyglot.open_reader` aus der \"chess\" Bibliothek aufgerufen. Diese Funktion liefert als Rückgabewert das Opening-Book, welches an die Stelle zurückgegeben wird, an der die Funktion `import_opening_book` aufgerufen wird.\n",
    "\n",
    "Sollte der Pfad in der Variable `book_location` keine Datei sein, so wird ein _File Not Found_-Fehler geworfen, der dabei den vermeintlichen Pfad mit übergibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_opening_book(book_location):\n",
    "        '''\n",
    "        load an opening book\n",
    "        raise an error if system cannot find the opening-book file\n",
    "        '''\n",
    "        if os.path.isfile(book_location):\n",
    "            return chess.polyglot.open_reader(book_location)\n",
    "        else:\n",
    "            raise FileNotFoundError(\n",
    "                errno.ENOENT, os.strerror(errno.ENOENT), book_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion zum Importieren des Opening-Books wird im Konstruktor der KI-Klasse aufgerufen, da das Opening-Book bei jeder Verwendung direkt zu Beginn von der KI benötigt wird und somit direkt verfügbar sein muss. Das bringt den Vorteil, dass eine Klassenvariable vorliegt, die von allen Funktionen der Klasse KI verwendet werden kann, sobald der Konstruktor ausgeführt wurde.\n",
    "\n",
    "Als Übergabewert wird die zuvor definierte Konstante `OPENING_BOOK_LOC` übergeben, die den Pfad zu einem Opening-Book enthält."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das Opening-Book verwenden zu können und aus diesem mögliche Eröffnungsstrategien verwenden zu können wird die Funktion `get_opening_move(self, board, opening_book)` benötigt, die als Übergabewerte das aktuelle Schachbrett und das importierte Book erhält.\n",
    "\n",
    "Der aktuelle Spielstand in Form des Schachbretts wird benötigt damit das Opening-Book weiß auf welche Situation reagiert werden muss.\n",
    "\n",
    "Der Sinn der Funktion `get_opening_move` ist es einen Schachzug als Objekt _chess.Move_ zurückzugeben, der laut des Opening-Books in dieser Situation angebracht ist. Dafür wird zuerst überprüft, ob die übergebene Variable `opening_book` durch den Konstruktor und dem damit einhergehenden Aufruf der Funktion `import_opening_book` korrekt initialisiert wurde.\n",
    "\n",
    "Sollte dies nicht der Fall sein wird von der Funktion ein `None` zurückgegeben. Der Wert `None` ist in der Sprache Python der leere Zustand. \n",
    "\n",
    "Falls das Opening-Book korrekt geladen werden konnte wird durch ein try-except versucht einen passenden Schachzug zu finden. Hierbei wird ein try-except verwendet, da die aufgerufene Funktion `opening_book.weighted_choice(board)` einen _Index Error_ wirft, falls das Opening-Book keinen passenden Zug kennt. Wenn dieser Fall eintreten sollte wird ebenfalls ein `None` zurückgegeben. Sollte jedoch das Buch einen passenden Zug haben, dann wird dieser Zug in eine Variable `main_entry` geladen und aus dieser der Zug extrahiert. Die Funktion `weighted_choice` wählt dabei aus den Zügen, die am besten zu dieser Situation passen, einen zufällig aus. Dies macht das Spiel weniger vorhersehbar, wenn der gleiche Gegner mehrfach gegen die KI spielt.\n",
    "\n",
    "Nachdem dies durchgeführt wurde, muss das Opening-Book geschlossen werden, damit es bei der nächsten Verwendung korrekt genutzt werden kann. Ebenfalls wird der erfolgreich extrahierte Zug zurückgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opening_move(board, opening_book):\n",
    "        '''\n",
    "        get the current board and return move, as string, for this situation\n",
    "        '''\n",
    "        if not (opening_book is None):\n",
    "            try:\n",
    "                main_entry = opening_book.weighted_choice(board)\n",
    "                move = main_entry.move\n",
    "                opening_book.close()\n",
    "                return move\n",
    "            except IndexError:\n",
    "                return None\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementierung des Iterative Deepening Algorithmus\n",
    "\n",
    "Um den besten Zug zu finen muss eine Schach-KI im Optimalfall alle möglichen Züge bis zum Ende des Spiels durchgehen, diese bewerten und den aussichtsreichsten Zug wählen. Da dies aber technisch nicht realistisch ist, werden die Züge nur bis zu einer gewissen Tiefe angeschaut und die Zustände über mitgegebene Evaluierungsfunktionen bewertet.\n",
    "\n",
    "Die KI geht dabei dann wie folgt vor: Alle möglichen Züge werden durchgegangen. Die daraus entstehenden Zustände werden analysiert und evaluiert. Dabei jedoch zählt nicht nur der direkt erreichbare Zustand , sondern auch die aus diesem Zustand erreichbaren Zustände und so weiter. Aus diesem Grund wird immer bis zu einer bestimmten Tiefe in die Züge hineingeschaut und die sich daraus ergebenden Zustände evaluiert.\n",
    "\n",
    "Um dies jedoch nicht fest immer bis zu einer bestimmten Tiefe durchgehen zu lassen, sondern variabel anzupassen, je nachdem wie viele Züge von dem gegebenen Zustand aus möglich sind, kann ein Zeitlimit dienen. Dabei wird anfangs die Tiefe auf 1 gesetzt und dann mittels des Minimax-Algorithmus die Züge evaluiert. Danach wird die Tiefe um 1 erhöht und erneut der Minimax-Algorithmus angewandt. Dies wird solange wiederholt, bis die angegebene Zeit abgelaufen ist. Dieser Algorithmus nennt sich \"Iterative Deepening\".\n",
    "\n",
    "Dem Algorithmus muss dazu der aktuelle Zustand sowie eine maximale Tiefe mitgegeben werden. Ist diese erreicht bricht der Algorithmus ab, unabhängig davon, ob das Zeitlimit überschritten ist oder nicht. Zunächst müssen beim Ausführen einige Werte festgelegt werden. Der folgende Algorithmus zeigt, wie der Prozess des Iterative Deepening implementiert ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_deepening(board, max_depth, evaluation_func, evaluation_funcs_dict):\n",
    "    depth = 1\n",
    "\n",
    "    start_time = int(time.time())\n",
    "    end_time = start_time + TIME_LIMIT\n",
    "    current_time = start_time\n",
    "\n",
    "    player = bool(board.turn)\n",
    "    best_possible_result = get_best_possible_result(board, player)\n",
    "\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    while current_time < end_time and depth <= max_depth:\n",
    "        move_val_dict = {}\n",
    "\n",
    "        best_value = float('-inf')\n",
    "        best_move = legal_moves[0]\n",
    "\n",
    "        for move in legal_moves:\n",
    "            board.push(move)\n",
    "            value = min_value(board, player, float('-inf'), float('inf'), depth - 1, end_time, evaluation_func, best_possible_result, evaluation_funcs_dict)\n",
    "            board.pop()\n",
    "            if value is False:\n",
    "                value = float('-inf')\n",
    "            move_val_dict[move] = value\n",
    "            if value == MAX_BOARD_VALUE:\n",
    "                return move\n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_move = move\n",
    "\n",
    "        legal_moves.sort(key=move_val_dict.get, reverse=True)\n",
    "        depth += 1\n",
    "        current_time = int(time.time())\n",
    "\n",
    "    return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst wird die Starttiefe auf 1 festgesetzt. Danach wird die Startzeit auf die aktuelle Zeit gesetzt und die Endzeit berechnet, indem auf die Startzeit das Zeitlimit addiert wird. Zudem wird der erste Wert für die aktuelle Zeit auf die Startzeit festgelegt.\n",
    "\n",
    "Anschließend wird für den Spieler, der aktuell am Zug ist, berechnet, was das bestmöglich zu erreichende Resultat ist. Dies wird mit der Funktion `get_best_possible_result` durchgeführt. Dies ist dazu gut, um finale Zustände dahingehend zu evaluieren, ob diese für den Nutzer die best mögliche Option ist (Sieg oder Unentschieden wenn Sieg nicht mehr möglich ist) und dementsprechend zu bewerten. Die Funktion sieht wie folgt aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_possible_result(board, player):\n",
    "    if player and board.has_insufficient_material(chess.WHITE):\n",
    "        return 0\n",
    "    if not player and board.has_insufficient_material(chess.BLACK):\n",
    "        return 0\n",
    "    if player and not board.has_insufficient_material(chess.WHITE):\n",
    "        return 1\n",
    "    if not player and not board.has_insufficient_material(chess.BLACK):\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabei muss der Funktion der aktuelle Zustand sowie der Spieler, der an der Reihe ist, mitgegeben werden. Ist der aktuelle Spieler der der weißen Figuren (player == True) und hat weiß unzureichende Materialien für einen Sieg, so ist der bestmögliche Zustand ein Patt. Das gleiche Ergebnis wird zurückgegeben, wenn der Spieler der der schwarzen Figuren ist (player == False) und schwarz unzureichende Materialien hat.\n",
    "\n",
    "Ist der Spieler jedoch weiß und er hat noch ausreichend Materialien, so wird der Wert 1 zurückgegeben, da ein Sieg noch erreichbar ist. Genauso wird für den schwarzen Spieler der Wert -1 zurückgegeben, falls er noch ausreichende Materialien besitzt, da dieser noch einen Sieg erreichen kann und der Wert -1 für einen Sieg von Schwarz steht.\n",
    "\n",
    "Nach dieser Abfrage wird der eigentliche Algorithmus des \"Iterative Deepening\" durchgeführt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabei wird zunächst eine Liste aller legalen Züge erstellt. Dann wird eine Schleife so lange durchlaufen, bis entweder die Zeit abgelaufen ist oder aber die maximale Tiefe erreicht ist. \n",
    "\n",
    "In dieser Schleife wird ein Dictionary aller Züge mit ihren berechneten Werte erstellt. Zudem werden Anfangswerte für die besten Züge und dessen Wert festgelegt. Der Anfangswert des besten Zugs wird auf den ersten Zug festgesetzt. Der Wert dieses wird auf den Wert \"- Unendlich\" gesetzt.\n",
    "\n",
    "Nun wird über alle legalen Züge iteriert und jeder temporär ausgeführt. Nun wird mittels des Minimax-Algorithmus der Wert dieses Zustands ermittelt, ehe der Zug zunächst wieder rückgängig gemacht wird. Dabei wird als Alpha \"- Unendlich\" und als Beta \"Unendlich\" mitgegeben.. Zudem wird die Tiefe auf einen Wert festgelegt, der um einen Wert geringer ist als die maximale Tiefe, da durch Aufruf der Funktion in die erste Tiefe hineingegangen wurde. Zudem wird die Zeit mitgegeben, zu der der Algorithmus enden muss, damit der Minimax Algorithmus dementsprechend endet und das Zeitlimit nicht überschreitet.\n",
    "\n",
    "Nachdem der Minimax-Algorithmus fertig durchlaufen ist, wird der Zug zunächst wiede rückgängig gemacht, damit dieser nicht das Spiel beeinflusst, sollte dieser nicht im Nachhinein gewählt werden. Zudem wird der Wert mit dem Zug zu dem Dictionary hinzugefügt.  Gleicht der berechnete Wert dem maximalen Wert für einen Zustand, ist also dementsprechend ein Sieg, wird der Zug direkt zurückgegeben, da mit diesem dann auf jeden Fall ein Sieg erreich werdne kann. Andernfalls wird der Wert verglichen, ob er besser ist als der aktuelle Wert. Ist dies der Fall, so wird der neue beste Wert auf den aktuell berechneten festgelegt, ebenso wie der beste Zug auf den der aktuellen Iteration gesetzt wird.\n",
    "\n",
    "Nachdem alle Züge durchlaufen wurden, wird die Liste aller legalen Züge an Hand der berechneten Werte sortiert, damit im nächsten Durchlauf die Züge in dieser Reihenfolge durchlaufen werden. Dies verbessert den Durchsatz beim Alpha Beta Pruning und garantiert zudem, dass der beste Wert der vergangenen Runde gewählt wird, falls der Minimax-Algorithmus beim Durchlaufen der nächst tieferen Tiefe das Zeitlimit erreicht, bevor die Runde komplett evaluiert werden konnte.\n",
    "\n",
    "Abschließend wird noch die Tiefe um 1 erhöht und die aktuelle Zeit auf die Systemzeit gesetzt, damit an Hand dieser entschieden werden kann, ob der Algorithmus noch weiter durchlaufen darf.\n",
    "\n",
    "Nachdem dann die Zeit abgelaufen ist und alle Züge in der für die angegebenen Zeit maximalen Tiefe evaluiert wurden, wird der best mögliche Zug zurückgegeben. Dieser wird dann von der KI ausgeführt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementierung des Minimax-Algorithmus mit Alpha-Beta-Pruning\n",
    "\n",
    "Um den bestmöglichen Zug zu erkennen, wird beim Minimax Algorithmus jeder Zug bis zu einer gewissen Tiefe betrachtet. Dabei wird unter der Prämisse gehandelt, dass auch der Gegner stets den besten Zug macht. Dies führt dazu, dass der bestmöglichste Zug ausgewählt wird (max), der erreichbar ist, wenn der Gegner mit dem für ihn jeweils besten Zug antwortet, der für den Spieler somit der schlechteste ist (min). \n",
    "\n",
    "Die Umsetzung dabei erfolgt in zwei Funktionen - `min_value` und `max_value`. Erstere berechnet dabei den schlecht möglichsten Ausgang für den Spieler aus einer bestimmten Position, also den besten Ausgang für den Gegner. Letztere berechnet den best möglichsten Ausgang. Beide Funktionen sind sehr ähnlich aufgebaut und in folgendem Code-Snippet zu sehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_value(board, player, alpha, beta, depth, time_limit, evaluation_func, best_possible_result, evaluation_funcs_dict):\n",
    "    v = float('inf')\n",
    "\n",
    "    if board.is_game_over() or depth == 0:\n",
    "        return evaluation_func(board, player, best_possible_result, evaluation_funcs_dict)\n",
    "    if int(time.time()) >= time_limit:\n",
    "        return False\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        board.push(move)\n",
    "        deeper_val = max_value(board, player, alpha, beta, depth -1, time_limit, evaluation_func, best_possible_result, evaluation_funcs_dict)\n",
    "        board.pop()\n",
    "        if deeper_val is False:\n",
    "            return False            \n",
    "        v = min(v, deeper_val)  \n",
    "\n",
    "        if v <= alpha:\n",
    "            return v\n",
    "        beta = min(beta, v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neben dem akteullen Zustand des Spiels Notation und dem Spieler, für den es den Zustand zu evaluieren gilt, wird außerdem eine Tiefe sowie ein Zeitlimit mitgegeben sowie die Werte Alpha und Beta. Alpha und Beta sind dabei dazu da, um den Minimax-Algorithmus zu beschleunigen, indem nicht jeder mögliche Zustand betrachtet wird. Durch diese Werte fallen nämlich solche weg, die direkt als irrelevant betrachtet werden können, da ohnehin bereits ein besserrer (im Fall von `min_value`) bzw. schlechterer (im Fall von `max_value`) Wert gefunden wurde.\n",
    "\n",
    "Zunächst wird überprüft, ob das Spiel bereits vorbei ist oder die mitgegebene Tiefe auf 0 liegt. In beiden Fällen wird der aktuelle Zustand direkt evaluiert und zurückgegeben. Ansonsten wird geprüft, ob das übergebene Zeitlimit bereits erreicht wurde. In dem Fall wird der maximal negative Wert zurück gegeben, damit dieser Zug keine weitere Beachtung mehr bei der endgültigen Auswahl findet.\n",
    "\n",
    "Ist auch dies nicht der Fall, werden alle von dem gegebenen Zustand aus erreichbaren Zustände durchgegangen. Dazu wird zunächst der Zug auf dem Schachbrett - hier board - ausgeführt. Dies ist dann der neue, erreichbare Zustand. Dieser wird dann in die nächst tiefere Iteration gegeben, bei der nun der maximale Wert gesucht wird. Dabei wird auch der Spieler mitgegeben sowie die Werte Alpha und Beta und das Zeitlimit ebenso wie die um eins reduzierte Tiefe. Danach wird der Zug zunächst wieder rückgängig gemacht. Ist bei der Evaluierung ein Wert dabei, der kleiner ist als das aktuelle v, wird dieser Wert als das neue v genommen. Andernfalls bleibt v beim akteullen Wert.\n",
    "\n",
    "Anschließend wird überprüft, ob der Wert v kleiner ist als der aktuelle Alpha Wert. Ist dies der Fall, muss der Pfad keine weitere Beachtung finden und es kann direkt v zurück gegeben werden. ist dies nicht der Fall, so wird Beta auf v gesetzt, falls dieser Wert kleiner als das aktuelle Beta ist. Nach Durchgang aller legalen Züge wird dann der sich aus all diesen Iterationen ergebende Wert v zurück gegeben.\n",
    "\n",
    "Die `max_value` Funktion läuft similar ab, mit dem einzigen Unterschied, dass hier der maximale statt der minmale Wert gesucht wird und dementsprechend die Vergleiche sowie Startwerte angepasst sind. Außerdem gibt dieser bei der um eins tieferen Iteration in die `min_value` Funktion, an der Stelle, an der diese in die `max_value` Funktion gibt. Der restliche Aufbau bleibt unverändert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_value(board, player, alpha, beta, depth, time_limit, evaluation_func, best_possible_result, evaluation_funcs_dict):\n",
    "    v = float('-inf')\n",
    "\n",
    "    if board.is_game_over() or depth == 0:\n",
    "        return evaluation_func(board, player, best_possible_result, evaluation_funcs_dict)\n",
    "    if int(time.time()) >= time_limit:\n",
    "        return False\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        board.push(move)\n",
    "        deeper_val = min_value(board, player, alpha, beta, depth -1, time_limit, evaluation_func, best_possible_result, evaluation_funcs_dict)\n",
    "        board.pop()\n",
    "        if deeper_val is False:\n",
    "            return False\n",
    "        v = max(v, deeper_val)\n",
    "\n",
    "        if v >= beta:\n",
    "            return v\n",
    "        alpha = max(alpha, v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit diesem Algorithmus wird ein Baum aus allen Pfaden erstellt, an Hand der der beste Zug ermittelt werden kann. Da es sich jedoch nur selten um Endzustände handelt, für die eine Bewertung trivial erfolgen kann, ist eine Evaluierung der Zustände nötig. Diese wird im nächsten Kapitel beschrieben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluierung eines gegebenen Schachbretts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um gegebene Zustände auch mitten im Spiel bewerten zu können, müssen diese an Hand bestimmter Kriterien bewertet werden können, die über Sieg oder Niederlage hinausgehen. Dazu gibt es verschiedene Ansätze, wie in Kapitel INSERT erläutert. Einige davon wurden im Laufe des Projektes umgesetzt und implementiert. Diese werden in diesem Kapitel erläutert. Zunächst jedoch gilt es aufzuzeigen, wie die Evaluierung der Zustände im generellen umgesetzt wird.\n",
    "\n",
    "Zunächst wird zum Evaluieren eines Zustandes jener Zustand sowie der Spieler, für den dieser zu evaluieren ist, in die Funktion `evaluate_board` gegeben, die die Evaluierung zentral verwaltet. Diese befindet sich in der `player/ai.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_board(board, player, best_possible_result, evaluation_funcs_dict):\n",
    "    player_color = chess.WHITE if player else chess.BLACK\n",
    "\n",
    "    if board.is_game_over():\n",
    "        result = get_board_result(board)\n",
    "        if result is best_possible_result:\n",
    "            return MAX_BOARD_VALUE\n",
    "        if result is best_possible_result * -1:\n",
    "            return -1 * MAX_BOARD_VALUE\n",
    "\n",
    "    evaluation_val = 0\n",
    "    for func, value in evaluation_funcs_dict.items():\n",
    "        if value > 0:\n",
    "            evaluation_val = evaluation_val + value * func(board, player_color)\n",
    "    return evaluation_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabei wird zunächst an Hand des Spielers die Farbe dieses ermittelt, die später bei den einzelnen Evaluierungsfunktionen benötigt wird.\n",
    "\n",
    "Dann wird für den Fall, dass der gegebene Zustand einem Endzustand gleicht, das Ergebnis dieses ermittelt. Gleicht dieses dem bestmöglichen Ergebnis, dass mittels der `get_board_result` Funktion zuvor ermittelt wurde (siehe INSERT), so wird der maximale Wert (Unendlich) für den Zusand zurückgegeben. Ist das Ergebnis des übermittelten Zustands jedoch eine Niederlage, so wird der maximale Wert umgekehrt und zurückgegeben (minus Unendlich). \n",
    "\n",
    "Gleicht der Zustand keinem Endzustand, so werden bestimmte Evaluationsfunktionen durchlaufen und aufaddiert. Dazu startet der Wert bei 0 und für jede Evaluierungsfunktion wird das Ergebnis dieser multipliziert mit einem festgelegten Faktor zu dem Gesamtwert aufaddiert. Die Faktoren sowie die durchzuführenden Evaluierungsfunktionen sind dabei abhängig vom Schwierigkeitsgrad der KI sowie vom Spielstatus (Eröffnung, Mittelspiel, Endspiel).\n",
    "\n",
    "Dabei werden zur Performanz-Steigerung jedoch nur Evaluierungsfunktionen durchgegangen, dessen Faktor höher als 0 liegt. Der Grund dafür ist, dass bestimmte Funktionne je nach Spielstatus leichter aus der Evaluierung herausgenommen werden können, ohne, dass das gesamte Dictionary angepasst werden muss und zudem keine unnötige Rechenzeit durch Berechnung eines Werts benötigt wird, der im Endeffekt ohnehin nicht zum Evaluierungswert aufaddiert wird.\n",
    "\n",
    "Der daraus entstehende Evaluierungswert, der zurückgegeben wird, gibt einen guten Aufschluss über den Wert des aktuellen Zustands. Dazu werden verschiedene Evaluierungsfunktionen verwendet, wie in folgendem Abschnitt zu sehen ist. Diese befinden sich in der Datei `misc/ai_evaluation_lib.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialbewertung\n",
    "\n",
    "Eine zentrale sowie einfache Bewertung ist dabei die Bewertung der vorhandenen Materialien auf dem Spielfeld. Dabei werden alle Figuren der jeweiligen Spieler zusammengezählt und je nach Figur mit einem Wert multipliziert. \n",
    "\n",
    "Dabei ist zunächst jedem Figurentyp ein Wert zuzuweisen. Üblicherweise werden Bauern dabei 1 Punkt, Türmen 5 Punkte, Springern sowie Läufern jeweils 3 Punkte und der Dame 9 Punkte zugeordnet. Dies geschieht über die Funktion `assign_piece_value()`. Dabei wird der Typ angegeben und die Punkte zurückgegeben. Zusätzlich kann angegeben werden, ob auch der König einen Wert zugewiesen bekommen soll. Diese werden dann über die `map` Funktion nach Farbe in der `get_value_by_color` Funktion für alle auf den Feldern befindlichen Figuren zusammengerechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAWN_VALUE = 1\n",
    "ROOK_VALUE = 5\n",
    "KNIGHT_VALUE = 3\n",
    "BISHOP_VALUE = 3\n",
    "QUEEN_VALUE = 9\n",
    "KING_VALUE = 15\n",
    "\n",
    "def assign_piece_value(piece_type, count_king=True):\n",
    "    return {\n",
    "        1: PAWN_VALUE,\n",
    "        2: KNIGHT_VALUE,\n",
    "        3: BISHOP_VALUE,\n",
    "        4: ROOK_VALUE,\n",
    "        5: QUEEN_VALUE,\n",
    "        6: KING_VALUE if count_king else 0\n",
    "    }.get(piece_type, 0)\n",
    "\n",
    "\n",
    "def get_value_by_color(board, color, count_king=True):\n",
    "    pieces_value = map(\n",
    "        lambda piece_type: len(board.pieces(piece_type, color)) * assign_piece_value(piece_type, count_king), chess.PIECE_TYPES)\n",
    "    return sum(pieces_value)\n",
    "\n",
    "\n",
    "def get_board_value(board, color, count_king=True):\n",
    "    white_value = get_value_by_color(board, chess.WHITE, count_king)\n",
    "    black_value = get_value_by_color(board, chess.BLACK, count_king)\n",
    "\n",
    "    return white_value - black_value if color is chess.WHITE else black_value - white_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um den Gesamtwert des Schachbretts zu berechnen muss zunächst der Wert aller weißer Figuren berechnet werden und von diesem der Wert aller schwarzen Figuren abgezogen werden. Je nach angegebenen Spieler wird für diesen ein positiver Wert zurückgegeben, wenn das Spiel zu dessen Gunsten verläuft und ein negativer, wenn dies nicht der Fall ist.\n",
    "\n",
    "Damit die Werte der Spieler berechnet werden können, wird die Anzahl aller Figurentypen der jeweiligen Farbe berechnet und diese mit dem Wert der Figurentypen multipliziert. Am Ende werden die Ergebnisse für alle Figurentypen zusammengezählt und zurückgegeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialbewertung attackierter Figuren\n",
    "\n",
    "Die Berechnung der attackierten Figuren ist ähnlich zu dem Vorgehen bei der Berechnung des Brettwerts. Dabei werden erst die Werte, der vom weißen Spieler attackierten Figuren berechnet und davon die Werte der vom schwarzen Spieler attackierten Figuren abgezogen. Auch hierbei ist ein positives Ergebnis zum Vorteil des angegebenen Spielers und ein negativer Wert zum Vorteil des Gegenübers. Ebenso gilt umso höher der Wert, desto deutlicher der Vorteil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attacked_pieces_value_by_color(board, attacker_color, defender_color):\n",
    "    attacked_squares = filter(lambda square: board.is_attacked_by(attacker_color, square) and not board.piece_at(\n",
    "        square) is None and board.piece_at(square).color is defender_color, chess.SQUARES)\n",
    "    attacked_pieces = map(lambda square: board.piece_at(square).piece_type, attacked_squares)\n",
    "    value = map(assign_piece_value, attacked_pieces)\n",
    "    return sum(value)\n",
    "\n",
    "\n",
    "def get_attacked_pieces_value(board, color):\n",
    "    white_factor = 1 if bool(board.turn) else 1/2\n",
    "    black_factor = 1/2 if bool(board.turn) else 1\n",
    "    \n",
    "    white_value = white_factor * get_attacked_pieces_value_by_color(board, chess.WHITE, chess.BLACK)\n",
    "    black_value = black_factor * get_attacked_pieces_value_by_color(board, chess.BLACK, chess.WHITE)\n",
    "\n",
    "    return white_value - black_value if color is chess.WHITE else black_value - white_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um diese Werte der attackierten Figuren zu berechnen wird jedes Feld durchgegangen. Daraus werden die Felder gefiltert, die von einer Figur der Farbe des Verteidigers belegt sind und von einer Figur der angreifenden Farbe attackiert werden können. Anschließend wird zu diesen Feldern der Typ der Figur zugeordnet, die sich auf dem Feld befindet. Daraufhin werden diesen ihre jeweiligen Werte zugeordnet und diese abschließend summiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positionsbewertung\n",
    "\n",
    "Um die Positionen der einzelnen Figuren zu bewerten, werden zunächst für jeden Figurentypen Matrizen benötigt, die über jedes Feld eine Aussage über den Wert der Position der Figur geben. Diese sind in Kapitel INSERT einsehbar. An Hand dieser Matrizen wird dann Aussage über den Wert getroffen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabei wird zunächst jedes Feld auf dem Schachbrett durchgegangen und die darauf befindliche Figur berechnet. Dies wird mittels einer verschachtelten Schleife gelöst, die zunächst alle Reihen durchgeht und dann die einzelnen Felder in dieser Reihe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "PAWN_POSITION_MATRIX =      np.array(   [[0,0,0,0,0,0,0,0],\n",
    "                                        [50,50,50,50,50,50,50,50],\n",
    "                                        [10,10,20,30,30,20,10,10],\n",
    "                                        [5,5,10,25,25,10,5,5],\n",
    "                                        [0,0,0,20,20,0,0,0],\n",
    "                                        [5,-5,-10,0,0,-10,-5,5],\n",
    "                                        [5,10,10,-20,-20,10,10,5],\n",
    "                                        [0,0,0,0,0,0,0,0]])\n",
    "\n",
    "KNIGHT_POSITION_MATRIX =    np.array(   [[-50,-40,-30,-30,-30,-30,-40,-50],\n",
    "                                        [-40,-20,0,0,0,0,-20,-40],\n",
    "                                        [-30,0,10,15,15,10,0,-30],\n",
    "                                        [-30,5,15,20,20,15,5,-30],\n",
    "                                        [-30,0,15,20,20,15,0,-30],\n",
    "                                        [-30,5,10,15,15,10,5,-30],\n",
    "                                        [-40,-20,0,5,5,0,-20,-40],\n",
    "                                        [-50,-40,-30,-30,-30,-30,-40,-50]])\n",
    "\n",
    "BISHOP_POSITION_MATRIX =    np.array(   [[-20,-10,-10,-10,-10,-10,-10,-20],\n",
    "                                        [-10,0,0,0,0,0,0,-10],\n",
    "                                        [-10,0,5,10,10,5,0,-10],\n",
    "                                        [-10,5,5,10,10,5,5,-10],\n",
    "                                        [-10,0,10,10,10,10,0,-10],\n",
    "                                        [-10,10,10,10,10,10,10,-10],\n",
    "                                        [-10,5,0,0,0,0,5,-10],\n",
    "                                        [-20,-10,-10,-10,-10,-10,-10,-20]])\n",
    "\n",
    "ROOK_POSITION_MATRIX =      np.array(   [[0,0,0,0,0,0,0,0],\n",
    "                                        [5,10,10,10,10,10,10,5],\n",
    "                                        [-5,0,0,0,0,0,0,-5],\n",
    "                                        [-5,0,0,0,0,0,0,-5],\n",
    "                                        [-5,0,0,0,0,0,0,-5],\n",
    "                                        [-5,0,0,0,0,0,0,-5],\n",
    "                                        [-5,0,0,0,0,0,0,-5],\n",
    "                                        [0,0,0,5,5,0,0,0]])\n",
    "\n",
    "QUEEN_POSITION_MATRIX =     np.array(   [[-20,-10,-10,-5,-5,-10,-10,-20],\n",
    "                                        [-10,0,0,0,0,0,0,-10],\n",
    "                                        [-10,0,5,5,5,5,0,-10],\n",
    "                                        [-5,0,5,5,5,5,0,-5],\n",
    "                                        [0,0,5,5,5,5,0,-5],\n",
    "                                        [-10,5,5,5,5,5,0,-10],\n",
    "                                        [-10,0,5,0,0,0,0,-10],\n",
    "                                        [-20,-10,-10,-5,-5,-10,-10,-20]])\n",
    "\n",
    "KING_POSITION_MATRIX =      np.array(   [[-30,-40,-40,-50,-50,-40,-40,-30],\n",
    "                                        [-30,-40,-40,-50,-50,-40,-40,-30],\n",
    "                                        [-30,-40,-40,-50,-50,-40,-40,-30],\n",
    "                                        [-30,-40,-40,-50,-50,-40,-40,-30],\n",
    "                                        [-20,-30,-30,-40,-40,-30,-30,-20],\n",
    "                                        [-10,-20,-20,-20,-20,-20,-20,-10],\n",
    "                                        [20,20,0,0,0,0,20,20],\n",
    "                                        [20,30,10,0,0,10,30,20]])\n",
    "\n",
    "def assign_piece_matrix(piece_type):\n",
    "    return {\n",
    "        1: PAWN_POSITION_MATRIX,\n",
    "        2: KNIGHT_POSITION_MATRIX,\n",
    "        3: BISHOP_POSITION_MATRIX,\n",
    "        4: ROOK_POSITION_MATRIX,\n",
    "        5: QUEEN_POSITION_MATRIX,\n",
    "        6: KING_POSITION_MATRIX\n",
    "    }.get(piece_type, np.zeros((8,8)))\n",
    "\n",
    "def get_board_positions_value(board, color):\n",
    "    sum = 0\n",
    "    for rank in range(0,8):\n",
    "        for file in range(0,8):\n",
    "            piece = board.piece_at(chess.square(file, rank))\n",
    "            if (piece and piece.color == color):\n",
    "                piece_pos_value = get_position_value_by_square(board, rank, file, color)\n",
    "                sum += piece_pos_value\n",
    "    return sum / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem die Figur ermittelt wurde wird diese, falls diese der angegebenen Farbe angehört, gemeinsam mit den Werten für Reihe und Spalte an die Funktion `get_position_value_by_square` übergeben. Nachdem diese den Wert zurückgegben hat wird dies zu der bisherigen Summe aufaddiert und am Ende die Summe aller Figuren geteilt durch 10 zurück gegeben. Der Divisor 10 rührt daher, dass die Positionen der einzelnen Figuren in dessen Matrizen recht hoch gewertet sind und somit insgesamt noch etwas abgeschwächt werden müssen, um die Funktion mit den restlichen Evaluierungsfunktionen ungefähr auf eine Bedeutungshöhe zu bringen.\n",
    "\n",
    "In der Funktion `get_position_value_by_square` wird mittels der Matrix der Wert der Figur an der gegebenen Position ermittelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_value_by_square(board, rank, file, color):\n",
    "    piece_type = board.piece_type_at(chess.square(file, rank))\n",
    "    piece_matrix = assign_piece_matrix(piece_type) if color == chess.BLACK else np.flip(assign_piece_matrix(piece_type))\n",
    "    piece_pos_value = piece_matrix[rank,file]\n",
    "    return piece_pos_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dazu wird zunächst der Typ der Figur auf dem gegebenen Feld ermittelt. Dann wird die dazu passende Matrix bestimmt und entsprechend gespiegelt, falls die Farbe des angegebenen Spielers weiß sein sollte, damit die Matrix mit den Positionen aus der Sicht des Spielers übereinstimmt.\n",
    "\n",
    "Schlussendlich wird der Wert in der Matrix über die Reihe und Spalte ermittelt und zurück gegeben. \n",
    "\n",
    "Um die Positionen des Gegners zu berechnen, kann folgende Funktion dienen, die die angegebene Farbe invertiert und so den Wert der gegnerischen Positionen berechnen und zurückgeben kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opp_board_positions_value(board, color):\n",
    "    opp_color = chess.WHITE if color is chess.BLACK else chess.BLACK\n",
    "    return -1 * get_board_positions_value(board, opp_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Königszonen-Sicherheit\n",
    "\n",
    "Ein weiterer, wichtiger Wert ist die Sicherheit des Königs bemessen an Hand der Figuren, die dessen Zone angreifen. \n",
    "\n",
    "Dazu wird diese Zone berechnet und dann alle Figuren, die diese Zone angreifen ermittelt. Mittels der in Kapitel INSERT vorgestellten Berechnung wird dann der Wert des Angriffs auf die Königszone berechnet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_king_zone_safety(board, color):\n",
    "    attacker_color = chess.WHITE if color == chess.BLACK else chess.BLACK\n",
    "    king_zone = calculate_king_zone(board, color)\n",
    "    attackers = get_attackers_by_squares(board, king_zone, attacker_color)\n",
    "    attack_weight = get_king_attack_weight(len(attackers))\n",
    "    value_of_attack = 0\n",
    "    for attacker in attackers:\n",
    "        value_of_attack += get_king_attack_constants(attacker.piece_type)\n",
    "    \n",
    "    return -1 * (value_of_attack * attack_weight) / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabei wird zuerst die Farbe des Angreifers berechnet, indem die gegebene Farbe umgekehrt wird. Danach wird mittels der Funktion `calculate_king_zone` die Königszone berechnet. Diese Funktion gibt eine Menge von Feldern zurück, die der Königszone angehören."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_king_zone(board, color):\n",
    "    king_zone = chess.SquareSet()\n",
    "    king_rank, king_file = get_piece_position(board, chess.Piece(chess.KING, color))\n",
    "\n",
    "    rank_range = range(0,4) if color == chess.WHITE else range(-3, 1)\n",
    "    for rank_summand in rank_range:\n",
    "        if (king_rank + rank_summand) in range(0, 8):\n",
    "            for file_summand in range(-1, 2):\n",
    "                if (king_file + file_summand) in range (0,8):\n",
    "                    king_zone.add(chess.square(king_file + file_summand, king_rank + rank_summand))\n",
    "    \n",
    "    return king_zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dies zu ermöglichen, wird zunächst die Position des Königs ermittelt. Dabei werden alle Felder durchgegangen bis der König der entsprechenden Farbe gefunden wurde. Dann wird Reihe sowie Spalte zurückgegeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_piece_position(board, piece):\n",
    "    for rank in range(0,8):\n",
    "        for file in range(0,8):\n",
    "            if board.piece_at(chess.square(file, rank)) == piece:\n",
    "                return rank, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden alle Felder der Königszone einzeln durchgegangen und zu der Menge an Feldern hinzugeführt. Dabei werden bei den Spaltel alle Felder bis 3 Felder in Richtung des Gegners durchgegangen und für jede Spalte ein Feld links bis zu einem Feld rechts von dem König mitgezählt. Dabei wird zuvor jeweils überprüft, ob sich die Spalte beziehungsweise die Reihe noch au fdem Spielfeld befinden. Ist dies der Fall, wird das Feld der Menge hinzugefügt und diese wird am Ende zurück gegeben.\n",
    "\n",
    "Als nächstes wir dann für diese Menge an Feldern ermittelt, welche Figuren diese Felder angreifen. Dies wird mittels der `get_attackers_by_squares` Funktion durchgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attackers_by_squares(board, square_set, attacker_color):\n",
    "    attacker_dict = {}\n",
    "    for square in square_set:\n",
    "        attacker_square_set = board.attackers(attacker_color, square)\n",
    "        for attacker_square in attacker_square_set:\n",
    "            attacker_piece = board.piece_at(attacker_square)\n",
    "            if not (attacker_piece.piece_type is chess.PAWN or attacker_piece.piece_type is chess.KING):\n",
    "                attacker_dict[attacker_piece] = attacker_dict.get(attacker_piece, 0) + 1\n",
    "    return attacker_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabei wird jedes Feld einzeln durchgegangen und für alle jeweils eine Menge an Figuren erstellt, die dieses Feld angreifen. Alle Angriefer werden dann einzeln durchgegangen und dessen Figurentyp ermittelt. Wenn dies weder ein Bauer noch ein König ist, wird die Figur einem Dictionary von allen Angreifern hinzugefügt. Der Wert dieses Eintrags setzt sich aus der Anzahl zusammen, wie viele Felder von dieser Figur angegriffen werden. Dieses Dictionary wird nach Durchgang jedes Feldes zurückgegeben.\n",
    "\n",
    "Nachdem dieses Dictionary zurückgegeben wurde, wird die Gewichtung der Attacke ermittelt. Dabei wird die Anzahl der verschiedenen Figuren, die die Zone angreifen, zur Hilfe genommen und ein ensprechender Wert zurückgegeben, wie in Kapitel INSERT beschrieben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_king_attack_weight(piece_counter):\n",
    "    return {\n",
    "        0: 0,\n",
    "        1: 0,\n",
    "        2: 50,\n",
    "        3: 75,\n",
    "        4: 88,\n",
    "        5: 94,\n",
    "        6: 97,\n",
    "        7: 99\n",
    "    }.get(piece_counter)\n",
    "\n",
    "def get_king_attack_constants(piece):\n",
    "    return {\n",
    "        chess.KNIGHT: 20,\n",
    "        chess.BISHOP: 20,\n",
    "        chess.ROOK: 40,\n",
    "        chess.QUEEN: 80\n",
    "    }.get(piece, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abschließend wird für jeden Angreifer noch der Wert dieses ermittelt, wie ebenfalls in Kapitel INSERT beschrieben, und diese alle aufaddiert. Dieser Wird wird dann mit dem berechneten Gewicht multipliziert und durch 1000 dividiert. Das Ergebnis aus dieser Berechnung wird dann zurückgegeben und gibt einen Aufschluss über die Sicherheit des Königs. Dies kann auch für die Sicherheit des gegnerischen Königs angewandt werden, indem schlicht die Farbe des Angreifers auf die eigene Farbe gesetzt wird. Auch hier kann die Sicherheit des gegnerischen Königs berechnet werden, indem die Funktion ausgeführt wird, nachdem zuvor die angegebene Farbe invertiert wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_opp_king_zone_safety(board, color):\n",
    "    opp_color = chess.WHITE if color is chess.BLACK else chess.BLACK\n",
    "    return -1 * calculate_king_zone_safety(board, opp_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobilität\n",
    "\n",
    "Bei der Berechnung eines Wertes zur Mobilität wird dieser an Hand der Differenz der legalen Züge von Spieler schwarz und Spieler weiß festgemacht. Dazu wird zunächst überprüft, ob es überhaut möglich ist einen Zug auszuführen. Ist dies nicht der Fall ist sowohl die Anzahl der Züge des Spielers, der am Zug ist, als auch die des nachfolgenden Spielers 0. Andernfalls wird ein zufälliger (hier: der erste) legaler Zug ausgeführt und der Wert der legalen Züge von diesem berechnet. Dabei wird aus Performanz Gründen nicht der Durchschnitt aller möglchen Züge berechnet, sondenr ein zufälliger Wert. Andernfalls hätte diese einzelne Evaluierungsfunktion so viel Zeit in Anspruch genommen, dass die Gesamtzahl an evaluierbaren Zügen um knapp ein Zehntel sinkt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_of_legal_moves_by_color(board, color):\n",
    "    player = chess.WHITE if bool(board.turn) else chess.BLACK\n",
    "    if player == color or len(list(board.legal_moves)) is 0:\n",
    "        return len(list(board.legal_moves))\n",
    "    else:\n",
    "        overall_legal_moves = 0\n",
    "        for action in board.legal_moves:\n",
    "            board.push(action)\n",
    "            overall_legal_moves += len(list(tmp_board.legal_moves))\n",
    "            board.pop()\n",
    "        return overall_legal_moves / len(list(board.legal_moves))\n",
    "    \n",
    "def calculate_mobility_value(board, color):\n",
    "    player = chess.WHITE if bool(board.turn) else chess.BLACK\n",
    "    current_turn_len = len(list(board.legal_moves))\n",
    "\n",
    "    if current_turn_len > 0:\n",
    "        board.push(list(board.legal_moves)[0])\n",
    "        next_turn_len = len(list(board.legal_moves))\n",
    "        board.pop()\n",
    "    else:\n",
    "        next_turn_len = 0\n",
    "    \n",
    "    if player == color:\n",
    "        return (current_turn_len - next_turn_len) / 10\n",
    "    else:\n",
    "        return (next_turn_len - current_turn_len) / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abschließend wird die Differenz der Anzahl der legalen Züge vom aktuellen Spielzustand und des berechneten möglichen nächstne Zustandes berechnet und zurückgegeben. Dabei wird entweder ein positiver Wert zurückgegeben, wenn der aktuelle Spieler mehr Züge hat. Dies ist der Fall, wenn der Spieler, der aktuell an der Reihe ist, dem entspricht, aus dessen Sicht der Zustand evaluiert wird. Andernfalls wird ein Wert aus der Sicht des Spielers zurückgegeben, der als nächstes am Zug ist. So wird gewährleistet, dass das Ergebnis stets aus Sicht des Spielers berechnet wird, aus dessen Sicht der Zustand evaluiert werden soll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starten des Spiels im Jupyter Notebook\n",
    "\n",
    "Um das Spiel auch im Jupyter Notebook starten zu können ist hier eine\n",
    "vereinfachte Variante des \\texttt{chess\\_master} vorzufinden. Dabei\n",
    "werden keine Spieler dynamisch erstellt, sondern abwechselnd der Nutzer und die KI nach einem Zug gefragt.\n",
    "\n",
    "Zum Ausgeben des aktuellen Zustands ist hier außerdem noch eine Funktion zu sehen, mittels der die Schachbretter als SVG im Jupyter Notebook ausgegeben werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display\n",
    "\n",
    "def print_board_svg(board):\n",
    "    display(SVG(chess.svg.board(board=board)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um im Nachhinein das Ergebnis ausgeben zu können, muss dies noch ermittelt werden, indem je nach Zustand das passende Ergebnis zurückgegeben wird:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_board_result(board):\n",
    "    if board.is_variant_loss():\n",
    "        return -1 if board.turn == chess.WHITE else 1\n",
    "    elif board.is_variant_win():\n",
    "        return 1 if board.turn == chess.WHITE else -1\n",
    "    elif board.is_variant_draw():\n",
    "        return 0\n",
    "\n",
    "    if board.is_checkmate():\n",
    "        return -1 if board.turn == chess.WHITE else 1\n",
    "    if board.can_claim_draw():\n",
    "        return 0\n",
    "    if board.is_seventyfive_moves() or board.is_fivefold_repetition():\n",
    "        return 0\n",
    "    if board.is_insufficient_material():\n",
    "        return 0\n",
    "    if not any(board.generate_legal_moves()):\n",
    "        return 0\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im vereinfachten Verwalter des Spiels wird auf ein Anlegen und Verwalten der Spielhistorie verzichtet. Stattdessen wird nach Erstellen des Spiels zunächst der Spieler nach seinem nächsten Zug gefragt und im nächsten Zug die KI aufgefordert einen zu berechnen. Danach wird der Zug zu dem board hinzugefügt und im nächsten Durchlauf wieder ausgegeben. Dies wird solange wiederholt bis das Spiel vorüber ist. Dazu sind zunächst noch alle nötigen Importe für das Spiel aufzulisten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chess\n",
    "import chess.svg\n",
    "import chess.polyglot\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "board = chess.Board()\n",
    "while not board.is_game_over():\n",
    "    print_board_svg(board)\n",
    "    if board.turn:\n",
    "        legal_moves = list(map(board.uci, board.legal_moves))\n",
    "        move = None\n",
    "        while move not in legal_moves:\n",
    "            print(\"Legal moves:\")\n",
    "            print(legal_moves)\n",
    "            move = input(\"Please enter your move: \")\n",
    "        move = chess.Move.from_uci(move)\n",
    "    else:\n",
    "        move = get_move(board)\n",
    "\n",
    "    board.push(move)\n",
    "\n",
    "result = get_board_result(board)\n",
    "if result is 1:\n",
    "    print(\"{} (White) has won\".format(players[0].name))\n",
    "elif result is -1:\n",
    "    print(\"{} (Black) has won\".format(players[1].name))\n",
    "else:\n",
    "    print(\"Draw\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
